---
title: 'Notes of novel view synthesis'
date: 2024-10-15
permalink: /posts/2024/10/blog-post/

---

CamCo 
------
1. 研究背景与主要贡献：
目前视频扩散模型已经成为能够生成高质量视频内容的生成式工具被广大用户使用。但是这些模型大多都不能提供精准的相机位姿控制，就给电影语言的表达带来了限制。为了解决这个问题，提出了CamCo，能够允许细粒度的相机位姿控制为image-to-video 生成。
① 使用Plucker 坐标表示准确的参数化的相机位姿输入，equip在预训练的image-to-video 生成器中
② 加强3d一致性，使用了一个极线注意力模块，加强feature maps的极限约束
③ 在真实世界视屏上微调CamCO，通过structure-from-motion算法
2. 技术与方法论：
corresponding ①：
基于Stable Video Diffusion模型训练了CamCo，SVD difffusion model学习逐步的降低高方差高斯噪声。作者通过light field network 和plucker 坐标收到启发，使用坐标来表示相机的内参和外参。
为了融合相机embeddings, 我们在预训练的视屏生成器中的每一个temporal attention block加入了简单的adapter layer。在每个tempal attention block 中，首先concatenate plucker coordinates 和network feature 在channel dimension上，然后将他们传出1*1的卷积层中去project  back 到原始的特征空间。
corresponding ②：
构建了Epipolar Constraint Attention，引入极线约束
corresponding ③：
由于缺乏动态场景的训练数据，模型很容易在静态场景下出现过拟合，只能有很少一部分的物体运动。
增强训练数据集+管理高质量样例
